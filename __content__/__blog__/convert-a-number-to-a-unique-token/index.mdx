---
title: Convert a number to a unique token
slug: is-it-used-or-not
author: Hynek Svacha
type: blog post
dateCreated: Mar 29, 2022 12:31
dateLastModified:
featuredImage:
categories:
  - javascript
keywords:
  - javascript
description:
---

# Convert a number to a unique token

## The problem

In this post, I will demonstrate a simple method for converting a number to a unique sequence of letters and numbers. We will take an integer (in a given range) and use it as an input to a function that will map it to a sequence of three capital ASCII characters followed by two integers. For instance, if we'll take a number 999, our function will give us `"AAJ99"`; for a million, we'll be given `"OUQ00"`:

```js
const toBase = (int, base, baseSymbols = "0123456789abcdef") => {
	let quot, rem, res = [];
  
  do {
  	quot = Math.trunc((quot || int) / base)
    rem = int % base
    res.unshift(baseSymbols[rem])
    console.log(quot)
  } while (quot !== 0)
  
  return res.join("")
}

console.log(toBase(5386, 16))
```

```js
// Converting numbers to tokens:
convertNumberToToken(999) // "AAJ99"
convertNumberToToken(1000000) // "OUQ00"

// ⚠️ Spoiler alert: we can reverse the tokens back to numbers:
convertTokenToNumber("AAJ99") // 999
convertTokenToNumber("OUQ00") // 1000000
```

We can think of it as a simple, naive, reversible [hash function](https://en.m.wikipedia.org/wiki/Hash_function).

## But why should I do that?

This is inspired by an [Exercism](https://exercism.org/) exercise. I was given a task to generate a bunch of unique random letters/numbers combinations. However, one of the tests were very strict: it was one checking if I'd be able to create _all the possible_ unique combinations. So I've got to create a list of them and filter out the ones already being used (my previous approach to just generate something random and check if it is unique scaled very poorly).

The number of combinations was in the order of hundred of thousands, so I was a little afraid about the performance. In most programming languages, numbers are less memory costly than strings are. So I decided to create a list of _numbers_ and map them to the derived strings just in time.

## Real life example

But let's look at one real-life example. The SNES version of [Prince of Persia](https://en.m.wikipedia.org/wiki/Prince_of_Persia) from early 90's used a very simple system of saves – if you successfully reached the end of the level, you were given an alphanumeric code, e. g. `"Y2CQWTB"`.

![Prince of Persia on SNES, end of level save code. Credit: https://www.youtube.com/watch?v=Io6zwExo3jw&t=1257s](assets/prince-of-persia-snes-save-code.png)

I don't know the exact implementation details, but I guess that this coded encoded the unique state of the game, so at least:

- the level reached
- the time remaining (probably in a fraction of seconds),
- the total health (hit points),
- the actual health (hit points).

On the top of it, there was some obfuscation that should prevent guessing the system too easily. In conclusion, we just need to somehow encode four numbers (rather low ones, except the time) using a system that gives us 78,364,164,096 combinations in total. That doesn't sound that hard, but there is one important thing: the system should be reversible, so if the player inputs a code, the game should set its state properly – or throw an error if the player just made the code up.

## Simple example: two six-sided dice

For a start, let's simplify the problem. Let's say we have a set of two six-sided dice 🎲🎲. If we'd throw them, we'll get one of the 36 unique results (6 \* 6 = 36).

So, how could we determine what throw result we get with e. g. n = 25?

```
// pseudo code

// this are our basic presumptions
if (n = 0) { result = [1, 1] }
if (n = (36 - 1)) { result = [6, 6] }

// but what about that?
if (n = random(0, 36 - 1)) { result = ? }
```

We'll use a little bit of simple math. Because the total count of possible results is the effect of multiplying by 6, we'll start by dividing the value by 6. This will give us two values: the quotient and the remainder.

The lowest possible throw result is represented by **0**.

**0 / 6 = 0, the remainder is 0.**

The highest possible throw result is represented by 36 - 1 = **35** (why `36 - 1`? Because we started with `0`, not `1`).

**35 / 6 = 5, the remainder is 5.**

So we got `[0, 0]` and `[5, 5]`. _But what do these numbers represent?_

Well, if we represent the sides of a dice as an _array of numbers_, these are the _indices_:

```js
const diceResults = [1, 2, 3, 4, 5, 6]

console.log(diceResults[0]) // 1
console.log(diceResults[1]) // 6
```

So what about our **25**? Well, **25 / 6 = 4, the remainder is 1.** So the result is `[4, 1]`, which means the actual throw results are **5 ⚄** and **2 ⚁**.

But why don't we just add 1 and yield the same result in a much simpler way (`[0, 0]` -> `[1, 1]`, `[5, 5]` -> `[6, 6]`)?

We can definitely do that, as long as the result is numeric. But if it's rather a symbol, like a character or a color, we'd probably need to store it in some list-like data structure anyway.

Putting it all together:

```js
const allPossibleResultsAsNumbers = Array.from(
  {
    length: 36,
  },
  (_, i) => i,
)

const get2D6Values = n => {
  const quotient = Math.floor(n / 6)
  const remainder = n % 6

  return [quotient, remainder]
}

const d6values = [1, 2, 3, 4, 5, 6]

const actualResults = allPossibleResultsAsNumbers.map(value => get2D6Values(value))

console.log(actualResults) // [[1, 1], [1, 2], [1, 3], ..[6, 6]]
```

## The actual alphanumeric pattern

All right, now for the actual alphanumeric pattern. I dont't want to fully spoil the actual above mentioned exercise, so I'll modify it slightly. So our ID will compose of **three** capital letters, followed by **two** digits: `AAA00..ZZZ99`

The letters will be the basic ASCII characters set (only uppercase):

```js
const CHARSET = "ABCDEFGHIJKLMNOPQRSTUVWXYZ"
```

This charset has 26 characters. Hence the number of possible combinations is 26 \* 26 \* 26 \* 10 \* 10 = 1,757,600. That's quite a lot!

We can again represent all combination as a list. `0` represents `AAA00`. Because we started with `0`, not `1`, we have to keep an eye on the "[off by one error](https://en.m.wikipedia.org/wiki/Off-by-one_error)" – the final number, which will represent `ZZZ99` won't be `1,757,600`, but `1,757,599`.

Let's pick a few numbers in the range and do the math.

First, we separate the numeric part from the letters. The numeric part will be preserved (just stringified and left-padded).

We'll do it by dividing the number by 100. The remainder will be the numeric part; from the the quotient, we'll derive the letters. We'll divide the first quotient by (26 \* 26); the resulting quotient is our first letter index. Then we divide the resulting remainder by 26; the last quotient is our second letter index and the last remainder the third letter index.

Note: How to order those indices (ot the charset itself) is up to you, it really doesn't matter as long as you keep the consistency.

Let's try the highest number in range:

**1,757,599 / 100 = 17575, the remainder is 99** (**99** is our _numeric part_)

**17,575 / (26 \* 26) = 25, the remainder is 675** (**25** is our _first letter index_)  
**675 / 26 = 25, the remainder is 25** (**25** and **25** are our _second_ and _third letter indices_)

Let's try some random number (devtools console gave me **744,202**)

**744202 / 100 = 7442, the remainder is 2** (**2** is our _numeric part_)

**7442 / (26 \* 26) = 11, the remainder is 6** (**11** is our _first letter index_)  
**6 / 26 = 0, the remainder is 6** (**0** is our _second letter index_, **6** is our _third one_)

Let's convert the math from above to javascript and test it:

```js
const CHARSET = "ABCDEFGHIJKLMNOPQRSTUVWXYZ"

const convertNumberToToken = n => {
  const numeric = String(n % 100).padStart(2, 0)
  const q1 = Math.floor(n / 100)

  const i1 = Math.floor(q1 / (26 * 26))
  const q2 = q1 % (26 * 26)
  const i2 = Math.floor(q2 / 26)
  const i3 = q2 % 26

  return `${CHARSET[i1]}${CHARSET[i2]}${CHARSET[i3]}${numeric}`
}

console.log(convertNumberToToken(1757599)) // "ZZZ99"
console.log(convertNumberToToken(744202)) // "LAG02"
```

Seems to be working fine!

## The reverse algorithm

Fine, we have our mapping function. But what about the reverse algorithm? Fortunately, it is not much different from the above one. It also uses just multiplication and addition.

Say we have a token, let's say `"CAB72"`. First We'll separate the letters from the numeric part. Then, we'll find of the letters in our `CHARSET` string.

```js
const CHARSET = "ABCDEFGHIJKLMNOPQRSTUVWXYZ"

const token = "CAB72"

const numeric = Number(token.slice(3)) // 72
const letters = token.slice(0, 3) // "CAB"

const indices = [...letters].map(letter => CHARSET.indexOf(letter)) // [2, 0, 1]
```

To decode the token, we need to remember, that we are actually using base 26 numeral system (or [hexavigesimal](https://en.m.wikipedia.org/wiki/List_of_numeral_systems#Standard_positional_numeral_systems), if you really want to impress your friends and family).

So what we need is to take the first index and multiply it by (26<sup>2</sup>); then add the second index multiplied by 26<sup>1</sup>; then add the third index multiplied by 26<sup>0</sup>.

If you ever tried to manually convert binary to decimal, this pattern may look familiar. That's because it's the same principle! Only the power is 26 instead of 2.

But don't forget about our numeric part! We need to further multiply the current value by 100, and finally, add the numeric part to the result.

In javascript, it could look like this:

```js
// disabling prettier: some of the parentheses are needless, but I prefer being explicit here
// prettier-ignore
const decoded = ((indices[0] * Math.pow(26, 2)) + (indices[1] * Math.pow(26, 1)) + (indices[2]) * Math.pow(26, 0)) * 100 + numeric
```

So putting it together into a `decodeToken` function:

```js
const CHARSET = "ABCDEFGHIJKLMNOPQRSTUVWXYZ"

const convertTokenToNumber = token => {
  const numeric = Number(token.slice(3))
  const letters = token.slice(0, 3)
  const indices = [...letters].map(letter => CHARSET.indexOf(letter))

  // disabling prettier: some of the parentheses are needless, but I prefer being explicit here
  // prettier-ignore
  return ((indices[0] * Math.pow(26, 2)) + (indices[1] * Math.pow(26, 1)) + (indices[2]) * Math.pow(26, 0)) * 100 + numeric
}

console.log(convertTokenToNumber("CAB72")) // 135372
```
